{
  "proxy_step": {
    "precision": 0.9090909090909091,
    "recall": 0.8823529411764706,
    "f1-score": 0.8955223880597014,
    "support": 34,
    "confused_with": {
      "goodbye": 2,
      "ask_proxy": 2
    }
  },
  "tutor_available": {
    "precision": 0.967741935483871,
    "recall": 0.967741935483871,
    "f1-score": 0.967741935483871,
    "support": 31,
    "confused_with": {
      "tutor_step": 1
    }
  },
  "goodbye": {
    "precision": 0.9032258064516129,
    "recall": 0.9032258064516129,
    "f1-score": 0.9032258064516129,
    "support": 31,
    "confused_with": {
      "greet": 2,
      "proxy_step": 1
    }
  },
  "greet": {
    "precision": 0.9411764705882353,
    "recall": 0.9795918367346939,
    "f1-score": 0.96,
    "support": 49,
    "confused_with": {
      "goodbye": 1
    }
  },
  "everyday_open_everyday_close": {
    "precision": 0.8333333333333334,
    "recall": 0.8333333333333334,
    "f1-score": 0.8333333333333334,
    "support": 30,
    "confused_with": {
      "ask_time_open_close": 3,
      "greet": 1
    }
  },
  "ask_day_open_close": {
    "precision": 0.8125,
    "recall": 0.7647058823529411,
    "f1-score": 0.787878787878788,
    "support": 51,
    "confused_with": {
      "ask_time_open_close": 8,
      "everyday_open_everyday_close": 4
    }
  },
  "ask_time_open_close": {
    "precision": 0.7708333333333334,
    "recall": 0.8043478260869565,
    "f1-score": 0.7872340425531915,
    "support": 46,
    "confused_with": {
      "ask_day_open_close": 8,
      "everyday_open_everyday_close": 1
    }
  },
  "tutor_step": {
    "precision": 0.9473684210526315,
    "recall": 0.972972972972973,
    "f1-score": 0.9599999999999999,
    "support": 37,
    "confused_with": {
      "tutor_available": 1
    }
  },
  "renew_book": {
    "precision": 0.9574468085106383,
    "recall": 0.9574468085106383,
    "f1-score": 0.9574468085106385,
    "support": 47,
    "confused_with": {
      "tutor_step": 1,
      "proxy_step": 1
    }
  },
  "ask_proxy": {
    "precision": 0.9393939393939394,
    "recall": 0.9117647058823529,
    "f1-score": 0.9253731343283583,
    "support": 34,
    "confused_with": {
      "renew_book": 2,
      "proxy_step": 1
    }
  },
  "accuracy": 0.8948717948717949,
  "macro avg": {
    "precision": 0.8982110957238504,
    "recall": 0.8977484048985843,
    "f1-score": 0.8977756236599495,
    "support": 390
  },
  "weighted avg": {
    "precision": 0.8946528123579208,
    "recall": 0.8948717948717949,
    "f1-score": 0.8945257228216899,
    "support": 390
  },
  "micro avg": {
    "precision": 0.8948717948717949,
    "recall": 0.8948717948717949,
    "f1-score": 0.8948717948717949,
    "support": 390
  }
}